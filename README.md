# Multi-Agent Planner

**LLM-powered system that solves coding tasks through agent collaboration.**

This project implements a multi-agent architecture using LLM-based agents, where each role has a specific function. A **Planner Agent** breaks down tasks, a **Developer Agent** writes code, a **QA Agent** validates execution, and a **Critic Agent** suggests improvements.

## âœ¨ Key Features

- ğŸ†“ **Free by Default** - Uses Groq's free Llama 3.3 70B API
- ğŸ”’ **Sandboxed Execution** - Safe code execution with multiple isolation methods
- ğŸ”„ **Auto-Retry** - Exponential backoff for API resilience
- ğŸ”Œ **Multi-Provider** - Switch between Groq, Gemini, Ollama, OpenAI, OpenRouter
- ğŸ’¾ **Persistent Memory** - Caches results to avoid redundant API calls
- ğŸ§© **Modular Design** - Easy to extend with new agents

---

## ğŸš€ Supported LLM Providers

| Provider | Cost | Models | Setup |
|----------|------|--------|-------|
| **Groq** | âœ… FREE | Llama 3.3 70B, Mixtral | [Get API Key](https://console.groq.com/) |
| **Google Gemini** | âœ… FREE tier | Gemini 2.0 Flash, 1.5 Pro | [Get API Key](https://aistudio.google.com/apikey) |
| **Ollama** | âœ… FREE (local) | Llama 3.2, CodeLlama, Mistral | [Install Ollama](https://ollama.ai/) |
| **OpenAI** | ğŸ’° Paid | GPT-4o, GPT-4 | [Get API Key](https://platform.openai.com/api-keys) |
| **OpenRouter** | ğŸ’° Pay-per-use | All models | [Get API Key](https://openrouter.ai/) |

---

## ğŸ”’ Security Features

### Sandboxed Code Execution

Generated code runs in isolated environments to prevent malicious operations:

| Method | Security | Requirements | Use Case |
|--------|----------|--------------|----------|
| `restricted` | â­â­â­ | None | Default, blocks dangerous operations |
| `docker` | â­â­â­â­â­ | Docker installed | Production, full isolation |
| `subprocess` | â­â­ | None | Basic timeout protection |

**Blocked operations:** `os.system`, `subprocess`, `eval`, `exec`, `__import__`, file I/O, network access

---

## Example Workflow

**Example user prompt:**  
*"Create a command-line tool that parses a CSV file and returns JSON-formatted summary statistics."*

System output:
1. **Planner** â†’ Breaks task into atomic subtasks
2. **Developer** â†’ Writes Python code for each subtask (sandboxed execution)
3. **QA Agent** â†’ Validates execution and correctness
4. **Critic** â†’ Reviews failed code, suggests fixes
5. **Developer** â†’ Revises and retries failed tasks (with exponential backoff)
6. **Assembler** â†’ Generates clean, deduplicated final program

---

## ğŸ“ Project Structure

```
multi_agent_planner/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ planner.py       # Task decomposition
â”‚   â”œâ”€â”€ developer.py     # Code generation + sandboxed execution
â”‚   â”œâ”€â”€ qa.py            # Code validation
â”‚   â”œâ”€â”€ critic.py        # Code review
â”‚   â””â”€â”€ base_agent.py    # Abstract base class
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ orchestrator.py  # Pipeline coordinator
â”‚   â”œâ”€â”€ llm_provider.py  # Multi-provider LLM abstraction
â”‚   â”œâ”€â”€ sandbox.py       # Sandboxed code execution
â”‚   â”œâ”€â”€ retry.py         # Exponential backoff retry logic
â”‚   â”œâ”€â”€ memory.py        # Persistent JSON memory
â”‚   â”œâ”€â”€ task_schema.py   # Task dataclass
â”‚   â””â”€â”€ assembler.py     # Code assembly
â”œâ”€â”€ output/              # Generated outputs
â”œâ”€â”€ memory/              # Agent memory caches
â”œâ”€â”€ logs/                # Session logs
â”œâ”€â”€ main.py              # Entry point
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ environment.yml      # Conda environment
â”œâ”€â”€ .env.example         # Environment template
â””â”€â”€ README.md
```

## ğŸ¤– Implemented Agents

| Agent | Role |
|-------|------|
| `PlannerAgent` | Breaks user prompts into atomic, executable subtasks |
| `DeveloperAgent` | Writes Python code with sandboxed execution |
| `QAAgent` | Verifies code execution and correctness |
| `CriticAgent` | Reviews failed code and suggests improvements |
| `Assembler` | Deduplicates and combines code into final output |

---

## ğŸš€ Quick Start

### 1. Clone and setup environment

```bash
git clone https://github.com/josepeon/multi_agent_planner.git
cd multi_agent_planner

# Option A: Using conda (recommended)
conda env create -f environment.yml
conda activate multi_agent_planner
pip install -r requirements.txt

# Option B: Using pip
pip install -r requirements.txt
```

### 2. Configure your LLM provider

Copy `.env.example` to `.env` and add your API key:

```bash
cp .env.example .env
```

**Option A: Use Groq (FREE & Fast - Recommended)**
```env
LLM_PROVIDER=groq
GROQ_API_KEY=gsk_your-key-here
```

**Option B: Use Google Gemini (FREE tier)**
```env
LLM_PROVIDER=gemini
GEMINI_API_KEY=your-key-here
```

**Option C: Use Ollama (FREE, runs locally)**
```bash
# First install Ollama and pull a model
ollama pull llama3.2
```
```env
LLM_PROVIDER=ollama
```

**Option D: Use OpenAI (Paid)**
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
```

### 3. Run the planner
```bash
python main.py
```

### 4. Follow the interactive prompt to generate your desired program!

---

## ğŸ“– API Usage

### LLM Provider

```python
from core.llm_provider import get_llm_client

# Use default provider from .env (Groq)
client = get_llm_client()
response = client.chat("Write a hello world in Python")

# Specify provider and model
client = get_llm_client(provider="groq", model="llama-3.3-70b-versatile")
response = client.chat(
    "Write a function to parse CSV",
    system_message="You are a senior Python developer"
)
```

### Sandboxed Execution

```python
from core.sandbox import execute_code_safely

# Execute code safely
result = execute_code_safely('print("Hello World")')
print(result["output"])  # "Hello World"
print(result["success"]) # True

# Dangerous code is blocked
result = execute_code_safely('import os; os.system("rm -rf /")')
print(result["success"]) # False
print(result["error"])   # "Security violation: 'os.system' is not allowed"

# Use Docker for maximum isolation
result = execute_code_safely(code, method="docker")
```

### Retry Logic

```python
from core.retry import retry_with_backoff, retry_llm_call

# Decorator pattern
@retry_with_backoff(max_retries=3, base_delay=1.0)
def call_api():
    return requests.get("https://api.example.com")

# Direct usage for LLM calls
result = retry_llm_call(lambda: client.chat("Hello"), max_retries=3)
```

---

## ğŸ§ª Testing

```bash
# Run a simple test
python -c "from core.llm_provider import get_llm_client; print(get_llm_client().chat('Say hello'))"

# Test sandbox
python -c "from core.sandbox import execute_code_safely; print(execute_code_safely('print(1+1)'))"
```

---

## ğŸ—ºï¸ Roadmap

- [ ] Web UI (Streamlit/Gradio)
- [ ] Async pipeline for parallel task execution
- [ ] RAG integration for documentation context
- [ ] Multi-file project generation
- [ ] Git integration for auto-commits
- [ ] Streaming output support

---

## ğŸ“„ License

MIT License - feel free to use this project for any purpose.

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.